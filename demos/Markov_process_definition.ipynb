{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "after-stability",
   "metadata": {},
   "source": [
    "# Ideas and definitions\n",
    "\n",
    "## References\n",
    "\n",
    "* Demgne, Jeanne Ady. Modélisation d’actifs industriels pour l’optimisation robuste de stratégies de maintenance. Thèse de doctorat. Pau, 2015.\n",
    "* Davis, Mark HA. \"Piecewise‐deterministic Markov processes: a general class of non‐diffusion stochastic models.\" Journal of the Royal Statistical Society: Series B (Methodological) 46.3 (1984): 353-376.\n",
    "\n",
    "## Markov process\n",
    "\n",
    "We consider a Markov process defined as follows.\n",
    "\n",
    "Let $m \\in\\mathbb{N}$ be the number of stages in the chain. \n",
    "\n",
    "At the n-th step, the inputs are made of:\n",
    "\n",
    "* the random vector $\\boldsymbol{U}_n \\in \\mathbb{R}^d$,\n",
    "* the deterministic vector $\\boldsymbol{x}_n \\in \\mathbb{R}^p$. \n",
    "\n",
    "for $n=1, 2, \\ldots, m$.\n",
    "\n",
    "The deterministic vector $\\boldsymbol{x}_n$ is often called the \"state\" of the chain at step $n$.\n",
    "\n",
    "The initial state of the Markov chain is $\\boldsymbol{x}_1 \\in \\mathbb{R}^p$, which is assumed to be given. \n",
    "\n",
    "At each step of the Markov chain, we generate a realization $\\boldsymbol{u}_n$ of the random vector $\\boldsymbol{U}_n$ and apply the transition function $\\boldsymbol{\\Phi}$ in order to compute the determininistic variable $\\boldsymbol{x}_{n+1}$. In the Markov chain, the state after the n-th step is driven by the transition function $\\boldsymbol{\\Phi}$ :\n",
    "\n",
    "$$\n",
    "\\boldsymbol{x}_{n+1} = \\boldsymbol{\\Phi}(\\boldsymbol{u}_n, \\boldsymbol{x}_n),\n",
    "$$\n",
    "\n",
    "for $n=1,...,m$. \n",
    "\n",
    "The output of the chain is the state $\\boldsymbol{x}_{m+1}$ after $m$ transitions. \n",
    "We may be interested into several quantities of interest (QoI) :\n",
    "\n",
    "* the expectation of $\\boldsymbol{x}_{m+1}$, denoted by \n",
    "\n",
    "$$\n",
    "\\mathbb{E}(\\boldsymbol{x}_{m+1}),\n",
    "$$\n",
    "\n",
    "* the probability that a function of state $\\boldsymbol{x}_{m+1}$ exceeds a given threshold $s$ : \n",
    "\n",
    "$$\n",
    "\\mathbb{P}(g(\\boldsymbol{x}_{m+1}) > s)\n",
    "$$\n",
    "\n",
    "where $g : \\mathbb{R}^p \\rightarrow \\mathbb{R}$ is a function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-behavior",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "We consider a Markov process with $m=2$ transitions. \n",
    "\n",
    "Assume that the inputs at step $n$ are \n",
    "* the random vector $\\boldsymbol{U}_n \\in \\mathbb{R}^3$,\n",
    "* the deterministic vector $\\boldsymbol{x}_n \\in \\mathbb{R}^2$. \n",
    "\n",
    "The initial state is $\\boldsymbol{x}_1 \\in \\mathbb{R}^2$.\n",
    "\n",
    "The first transition is:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{x}_2 = \\boldsymbol{\\Phi}(\\boldsymbol{u}_1, \\boldsymbol{x}_1),\n",
    "$$\n",
    "\n",
    "where $\\boldsymbol{u}_1 \\in \\mathbb{R}^3$ is a realization of the random vector $\\boldsymbol{U}_n$. \n",
    "\n",
    "Similarily, the second transition is:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{x}_3 = \\boldsymbol{\\Phi}(\\boldsymbol{u}_2, \\boldsymbol{x}_2),\n",
    "$$\n",
    "\n",
    "where $\\boldsymbol{u}_2 \\in \\mathbb{R}^3$ is a realization of the random vector $\\boldsymbol{U}_n$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-value",
   "metadata": {},
   "source": [
    "## Two mathematically equivalent visions\n",
    "\n",
    "This Markov process is presented in the following figure. The two figures on the left and right of the image are representing the same Markov chain. On the left, we consider that the important input is the deterministic state $\\boldsymbol{x}_n$ and that the random input $\\boldsymbol{u}_n$ is an \"auxiliary\" or \"exogenous\" parameter. On the right, we consider that the important input is the random input $\\boldsymbol{u}_n$ and that $\\boldsymbol{x}_n$ is a parameter. \n",
    "\n",
    "![Markov process](../figures/markov_process.png)\n",
    "\n",
    "Both figures represent the same chain, but, depending on the context, one of them might be more significant. In OpenTURNS, the input of a function is assumed to be random, the deterministic input $\\boldsymbol{x}_n$ is a parameter and the output $\\boldsymbol{x}_{n + 1}$ is a function of the inputs, so that the right figure is more appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-platform",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
